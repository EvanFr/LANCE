This work claims that the LANCE pipeline is reproducible with state of the art LLMs making them extract and label Indicators of Compromise (IoCs) reliably.

To support this claim we use 4 more state of the art LLMs as the backbone model for LANCE. We evaluate their performance on the PRISM dataset on claim 8.
Namely we use:
- Llama 3.3 70b
- Gemma 3 27b
- Nvidia Llama 3.1 Nemotron 70b
- Gemini 2.0 Flash

All four models are being used pre-trained only for inference.
The first three models (Llama, Gemma, and Nemotron) are open source and the inference is run locally using their implementation available on HuggingFace.
For Gemini the reviewer(s) will need access to the corresponding API services provided by Google.
Before running run.sh make sure you added your API key in the corresponding field at the top of the script.

There is the to option run each LACNE version with a limited number of reports. This way the reviewer(s) can verify the functionality of LANCE without having long wait times.
This can be done for example for 2 reports, by running:

./run.sh 2

In case there is no integer given the script will revert to running each LACNE version with all 50 of the reports.

In case this is not possible for the reviewer(s), we provide evaluation of the results we got running this experiment in claim 8.
